// Template configuration file - Copy this file to config.js and replace with your actual values
const config = {
    // LLM API Configuration
    llm: {
        apiKey: 'YOUR_API_KEY_HERE', // Replace with your actual API key
        model: 'gpt-3.5-turbo', // Default model to use
        maxTokens: 150, // Maximum tokens for responses
        temperature: 0.7 // Temperature for response generation
    }
};

// Export the configuration
export default config; 